#' A Function to Read JAX Envision® activity CSVs
#'
#' This function allows you to read activity CSVs generated by the JAX Envision® software.
#' @param csv File path for the Envision® CSV.
#' @param tz Time zone for the study. If left as \code{NULL}, the function will attempt to assume a time zone and throw a warning.
#' @param occupancy_normalize Should the function normalize activity by cage occupancy? Default: \code{FALSE}.
#' @param metrics Should the function expect cage or animal level activity metrics? Default: \code{"cage"}
#' @returns A \code{tibble} with experimental data optimally formatted for downstream analysis.
#' @keywords Envision
#' @export
#' @examples
#' # Writing test CSV file
#' activity_csv <- tempfile("testactivity", fileext = ".csv")
#' readr::write_lines(csv_lines, file = activity_csv)
#'
#' # Reading in test CSV file
#' activity <- read_activity_csv(csv = activity_csv, tz = "US/Pacific")
#' dplyr::glimpse(activity)

read_activity_csv <- function(csv, tz = NULL, occupancy_normalize = FALSE,
                              metrics = c("cage","animal")) {

  # Ensuring required packages are loaded
  stopifnot(requireNamespace("readr", quietly = TRUE))
  stopifnot(requireNamespace("janitor", quietly = TRUE))
  stopifnot(requireNamespace("dplyr", quietly = TRUE))
  stopifnot(requireNamespace("lubridate", quietly = TRUE))
  stopifnot(requireNamespace("tibble", quietly = TRUE))

  # Reading in raw data
  activity_data <- readr::read_csv(csv, show_col_types = FALSE) |>
    janitor::clean_names() |>
    tibble::as_tibble()

  # Starting by listing compatible time zones
  compatible_tzones <- activity_data |>
    dplyr::mutate(startlocal_utc = paste(start_date_local, start_time_local),
                  startlocal_utc = lubridate::ymd_hms(startlocal_utc,
                                                      tz = "UTC"),
                  utc_offset_h = as.numeric(startlocal_utc - start)) |>
    dplyr::group_by(utc_offset_h) |>
    dplyr::mutate(min_starttime = min(start)) |>
    dplyr::select(utc_offset_h, min_starttime) |>
    dplyr::summarize(min_starttime_utc = min(min_starttime)) |>
    dplyr::left_join(timezones_df, by = "utc_offset_h")

  # Assigning time zone
  if (is.null(tz)) {
    # Attempting to automagically impute an assumed time zone if tz is NULL
    # Identifying all unique UTC offsets in the dataset
    # Then finding compatible assumed time zones
    probable_tzones = compatible_tzones |>
      dplyr::filter(assume == 1) |>
      dplyr::ungroup() |>
      dplyr::mutate(tz_isdst = lubridate::dst(
        lubridate::with_tz(min_starttime_utc, tzone = tz_name))) |>
      dplyr::filter(is_dst == tz_isdst)

    # Getting unique time zones that are assumed.
    unique_tzs <- probable_tzones |>
      dplyr::pull(tz_name) |>
      unique()

    # Setting time zone according to a series of conditions
    if (length(unique_tzs) == 1) {
      tz_assume <- unique_tzs
    } else {
      unique_tzs_override <- probable_tzones |>
        dplyr::filter(override == 1) |>
        dplyr::pull(tz_name) |>
        unique()
      if (length(unique_tzs_override) == 1) {
        tz_assume = unique_tzs_override
      } else {
        # Throwing an error if a time zone cannot be unambiguously assumed
        stop("could not assume a time zone unambiguously.")
      }
    }
    activity_data <- activity_data |>
      dplyr::mutate(start = lubridate::with_tz(start, tzone = tz_assume),
                    tzone = tz_assume)
    # Throwing a warning if
    warning(paste0("Assuming time zone: ", tz_assume,
                   ". Set time zone explicitly if different."))
  } else {
    if (tz %in% timezones_df$tz_name) {
      activity_data <- activity_data |>
        dplyr::mutate(start = lubridate::with_tz(start, tzone = tz),
                      tzone = tz)
      if (!(tz %in% (compatible_tzones |> dplyr::pull(tz_name)))) {
        warning(paste("UTC offset for the", tz,
                      "time zone mismatches suggested time zones."))
      }
    } else {
      stop(paste("time zone", tz, "is not a system time zone."))
    }
  }

  return(activity_data)
}

#' Dummy JAX Envision® activity CSV lines formatted the same as exported activity data.
#'
#' A dataset containing four lines of fabricated JAX Envision® activity data.
#'  These lines follow the format of a JAX Envision® activity CSV.
#'  When read properly, the lines for cage-level data have raw column titles as follows:
#'
#'  \itemize{
#'    \item \code{start}. the date and time at the start of the aggregation bin (in UTC).
#'    \item \code{start_date_local}. the start date (in the time zone in which the data were collected).
#'    \item \code{start_time_local}. the start time (in the time zone in which the data were collected).
#'    \item \code{study_code}. a unique code for each study.
#'    \item \code{aggregation_seconds}. the number of seconds aggregated to generate this dataset (3600 is 1 hour).
#'    \item \code{group_name}. a user-defined group name, often used to label experimental groups of interest.
#'    \item \code{cage_name}. the name of the cage that the data represent.
#'    \item \code{animals_cage_quantity}. the number of animals in the cage, sometimes called cage density or occupancy.
#'    \item \code{light_cycle}. whether the data were collected in the light or dark cycle.
#'    \item \code{movement_mean_per_cage_cm_s_hour}. cage-level movement in cm/s for a specified period of time (1 hour in this example)
#'    \item \code{wheel_occupancy_mean_per_cage_animals_hour}. amount of time spent on the wheel at the cage level.
#'    \item \code{food_occupancy_mean_per_cage_animals_hour}. amount of time spent in proximity to the food hopper at the cage level.
#'    \item \code{water_occupancy_mean_per_cage_animals_hour}. amount of time spent in proximity to the water bottles at the cage level.
#'    \item \code{tzone}. time zone of the dataset.
#'  }
#'
#' @docType data
#' @keywords datasets
#' @name csv_lines
#' @usage data(csv_lines)
#' @format a character vector with 5 lines, the first line is a header.
NULL
